#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì œì£¼ë„ AI êµì‚¬ ì–´ì‹œìŠ¤í„´íŠ¸ - Streamlit ì›¹ ì•±
ì›¹ ê¸°ë°˜ AI ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
"""

import streamlit as st
import os
import json
from datetime import datetime
from typing import List, Dict, Any

# OpenAI API í˜¸í™˜ì„± ë¬¸ì œ í•´ê²°
try:
    from openai import OpenAI
    OPENAI_NEW_API = True
except ImportError:
    st.error("âŒ openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.info("ğŸ’¡ pip install openaië¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
    st.stop()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="êµì‚¬ë“¤ì„ ìœ„í•œ ì–´ì‹œìŠ¤í„´íŠ¸ ë´‡",
    page_icon="ğŸï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "messages" not in st.session_state:
    st.session_state.messages = []
if "client" not in st.session_state:
    st.session_state.client = None

def load_api_key() -> bool:
    """OpenAI API í‚¤ ë¡œë“œ"""
    try:
        from dotenv import load_dotenv
        load_dotenv()
        
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key or api_key == "your_api_key_here":
            return False
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        st.session_state.client = OpenAI(api_key=api_key)
        return True
        
    except Exception as e:
        st.error(f"âŒ API í‚¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

def get_ai_response(message: str, model: str = "gpt-3.5-turbo", max_tokens: int = 1000) -> str:
    """AI ì‘ë‹µ ìƒì„±"""
    if not st.session_state.client:
        return "âŒ OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = """ë‹¹ì‹ ì€ ì œì£¼ë„ ê³ ë“±í•™êµ êµì‚¬ë“¤ì„ ìœ„í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì£¼ìš” ì—­í• :
- ìˆ˜ì—… ê³„íš ë° ìë£Œ ì œì‘ ì§€ì›
- í•™ìƒ ìƒë‹´ ë° ì§„ë¡œ ì§€ë„ ì¡°ì–¸
- í•™ë¶€ëª¨ ìƒë‹´ ì§€ì›
- ì œì£¼ë„ íŠ¹í™” êµìœ¡ ìë£Œ ì œê³µ
- í–‰ì • ì—…ë¬´ ë° ê³µì§€ì‚¬í•­ ì‘ì„± ì§€ì›

ì œì£¼ë„ íŠ¹í™” ì •ë³´:
- ìì—° ìƒíƒœ: í•œë¼ì‚°, í•´ë³€, ì˜¤ë¦„, ë™êµ´ ë“±
- ë¬¸í™” ì²´í—˜: ì œì£¼ ì „í†µ ë¬¸í™”, ê´€ìŠµ, ìŒì‹
- í˜„ì¥í•™ìŠµ: ì§€ì—­ ìì› í™œìš© ì²´í—˜ êµìœ¡
- ì—­ì‚¬ ì´í•´: ì œì£¼ë„ì˜ ì—­ì‚¬ì™€ íŠ¹ì„±

í•­ìƒ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µí•˜ë©°, 
êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”."""

        # ë©”ì‹œì§€ ì¤€ë¹„
        messages = [
            {"role": "system", "content": system_prompt}
        ]
        
        # ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (ìµœê·¼ 10ê°œ)
        for msg in st.session_state.messages[-10:]:
            messages.append({"role": msg["role"], "content": msg["content"]})
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        messages.append({"role": "user", "content": message})
        
        # OpenAI API í˜¸ì¶œ
        response = st.session_state.client.chat.completions.create(
            model=model,
            messages=messages,
            max_tokens=max_tokens,
            temperature=0.7
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"âŒ AI ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}"

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    st.title("ğŸï¸ êµì‚¬ë“¤ì„ ìœ„í•œ ì–´ì‹œìŠ¤í„´íŠ¸ ë´‡")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # API í‚¤ ìƒíƒœ í™•ì¸
        if not load_api_key():
            st.error("âš ï¸ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEY=ì‹¤ì œ_API_í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.stop()
        else:
            st.success("âœ… OpenAI API ì—°ê²°ë¨")
        
        # ëª¨ë¸ ì„ íƒ
        model = st.selectbox(
            "ğŸ¤– AI ëª¨ë¸ ì„ íƒ",
            ["gpt-3.5-turbo", "gpt-4o-mini"],
            index=0
        )
        
        # ì‘ë‹µ ê¸¸ì´ ì„¤ì •
        max_tokens = st.slider(
            "ğŸ“ ì‘ë‹µ ê¸¸ì´",
            min_value=100,
            max_value=2000,
            value=1000,
            step=100
        )
        
        # ëŒ€í™” ê¸°ë¡ ê´€ë¦¬
        st.markdown("---")
        st.subheader("ğŸ—‚ï¸ ëŒ€í™” ê´€ë¦¬")
        
        if st.button("ğŸ§¹ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"):
            st.session_state.messages = []
            st.rerun()
        
        if st.button("ğŸ“¥ ëŒ€í™” ë‚´ë³´ë‚´ê¸°"):
            if st.session_state.messages:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"ëŒ€í™”ê¸°ë¡_{timestamp}.json"
                
                # JSON íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°
                with open(filename, "w", encoding="utf-8") as f:
                    json.dump(st.session_state.messages, f, ensure_ascii=False, indent=2)
                
                st.success(f"âœ… ëŒ€í™” ê¸°ë¡ì´ {filename}ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("ğŸ“ ì €ì¥í•  ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë¹ ë¥¸ ì§ˆë¬¸ ë²„íŠ¼ë“¤
        st.markdown("---")
        st.subheader("ğŸ’¡ ë¹ ë¥¸ ì§ˆë¬¸")
        
        quick_questions = [
            "ì œì£¼ë„ í˜„ì¥í•™ìŠµ ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”",
            "í•™ìƒ ìƒë‹´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”",
            "ì œì£¼ë„ íŠ¹í™” ìˆ˜ì—… ìë£Œ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”",
            "í•™ë¶€ëª¨ ìƒë‹´ ê°€ì´ë“œë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”"
        ]
        
        for question in quick_questions:
            if st.button(question, key=f"quick_{question[:10]}"):
                # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
                st.session_state.messages.append({"role": "user", "content": question})
                
                # AI ì‘ë‹µ ìƒì„±
                ai_response = get_ai_response(question, model, max_tokens)
                st.session_state.messages.append({"role": "assistant", "content": ai_response})
                
                st.rerun()
    
    # ë©”ì¸ ì±„íŒ… ì˜ì—­
    st.subheader("ğŸ’¬ AI ì–´ì‹œìŠ¤í„´íŠ¸ì™€ ëŒ€í™”í•˜ê¸°")
    
    # ëŒ€í™” í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ğŸ¤– AIê°€ ì‘ë‹µì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                response = get_ai_response(prompt, model, max_tokens)
                st.markdown(response)
        
        # AI ì‘ë‹µì„ ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        st.session_state.messages.append({"role": "assistant", "content": response})
    
    # ëŒ€í™” í†µê³„
    if st.session_state.messages:
        st.markdown("---")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ì´ ëŒ€í™” ìˆ˜", len(st.session_state.messages) // 2)
        
        with col2:
            user_messages = len([m for m in st.session_state.messages if m["role"] == "user"])
            st.metric("ì‚¬ìš©ì ë©”ì‹œì§€", user_messages)
        
        with col3:
            ai_messages = len([m for m in st.session_state.messages if m["role"] == "assistant"])
            st.metric("AI ì‘ë‹µ", ai_messages)

if __name__ == "__main__":
    main()
